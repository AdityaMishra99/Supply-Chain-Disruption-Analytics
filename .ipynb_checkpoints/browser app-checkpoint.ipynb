{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1b4a9c1-b450-4a0c-8f56-9fe168a36682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-25 20:37:40.286 Please replace `use_container_width` with `width`.\n",
      "\n",
      "`use_container_width` will be removed after 2025-12-31.\n",
      "\n",
      "For `use_container_width=True`, use `width='stretch'`. For `use_container_width=False`, use `width='content'`.\n",
      "2026-02-25 20:37:40.288 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-25 20:37:40.290 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-25 20:37:40.292 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-25 20:37:40.293 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-25 20:37:40.295 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-25 20:37:40.295 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-25 20:37:40.296 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-25 20:37:40.298 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-25 20:37:40.299 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-25 20:37:40.300 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2026-02-25 20:37:40.301 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'supply_chain_recovery_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNoSessionContext\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\streamlit\\elements\\spinner.py:116\u001b[39m, in \u001b[36mSpinnerMixin.spinner\u001b[39m\u001b[34m(self, text, show_time, _cache, width)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     create_transient, clear_transient = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdg\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_transient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m        \u001b[49m\u001b[43melement_proto\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayout_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayout_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m NoSessionContext:\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# Means we are not in a script thread, so we will just yield and return\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\streamlit\\delta_generator.py:636\u001b[39m, in \u001b[36mDeltaGenerator._transient\u001b[39m\u001b[34m(self, element_proto, layout_config)\u001b[39m\n\u001b[32m    629\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Provides the factory functions for creating and clearing transient elements.\u001b[39;00m\n\u001b[32m    630\u001b[39m \u001b[33;03mIt preserves the delta path, transient index, and the set of transient elements.\u001b[39;00m\n\u001b[32m    631\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    634\u001b[39m \u001b[33;03m- clear_transient_element: Clears the transient element.\u001b[39;00m\n\u001b[32m    635\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m636\u001b[39m transient_cursor = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_transient_cursor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    637\u001b[39m delta_path = transient_cursor.delta_path\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\streamlit\\delta_generator.py:441\u001b[39m, in \u001b[36mDeltaGenerator._get_transient_cursor\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    440\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cursor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m441\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NoSessionContext(\u001b[33m\"\u001b[39m\u001b[33mCursor is not set\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cursor.get_transient_cursor()\n",
      "\u001b[31mNoSessionContext\u001b[39m: Cursor is not set",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;129m@st\u001b[39m.cache_resource\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_model\u001b[39m():\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m joblib.load(\u001b[33m\"\u001b[39m\u001b[33msupply_chain_recovery_model.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m model = \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# ----------------------------------\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# PDF Report Generator\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# ----------------------------------\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_pdf_report\u001b[39m(input_df, prediction, risk_level, importance_df):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\streamlit\\runtime\\caching\\cache_utils.py:281\u001b[39m, in \u001b[36mCachedFunc.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    279\u001b[39m         spinner_message = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m(...)`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m281\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_or_create_cached_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspinner_message\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\streamlit\\runtime\\caching\\cache_utils.py:326\u001b[39m, in \u001b[36mCachedFunc._get_or_create_cached_value\u001b[39m\u001b[34m(self, func_args, func_kwargs, spinner_message)\u001b[39m\n\u001b[32m    318\u001b[39m spinner_or_no_context = (\n\u001b[32m    319\u001b[39m     get_dg_singleton_instance().main_dg.spinner(\n\u001b[32m    320\u001b[39m         spinner_message, _cache=\u001b[38;5;28;01mTrue\u001b[39;00m, show_time=\u001b[38;5;28mself\u001b[39m._info.show_time\n\u001b[32m   (...)\u001b[39m\u001b[32m    323\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext()\n\u001b[32m    324\u001b[39m )\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m spinner_or_no_context:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_cache_miss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\streamlit\\runtime\\caching\\cache_utils.py:385\u001b[39m, in \u001b[36mCachedFunc._handle_cache_miss\u001b[39m\u001b[34m(self, cache, value_key, func_args, func_kwargs)\u001b[39m\n\u001b[32m    381\u001b[39m \u001b[38;5;66;03m# We acquired the lock before any other thread. Compute the value!\u001b[39;00m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._info.cached_message_replay_ctx.calling_cached_function(\n\u001b[32m    383\u001b[39m     \u001b[38;5;28mself\u001b[39m._info.func\n\u001b[32m    384\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m     computed_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[38;5;66;03m# We've computed our value, and now we need to write it back to the cache\u001b[39;00m\n\u001b[32m    388\u001b[39m \u001b[38;5;66;03m# along with any \"replay messages\" that were generated during value computation.\u001b[39;00m\n\u001b[32m    389\u001b[39m messages = \u001b[38;5;28mself\u001b[39m._info.cached_message_replay_ctx._most_recent_messages\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;129m@st\u001b[39m.cache_resource\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_model\u001b[39m():\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjoblib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msupply_chain_recovery_model.pkl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\joblib\\numpy_pickle.py:735\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filename, mmap_mode, ensure_native_byte_order)\u001b[39m\n\u001b[32m    733\u001b[39m         obj = _unpickle(fobj, ensure_native_byte_order=ensure_native_byte_order)\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    736\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m _validate_fileobject_and_memmap(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m (\n\u001b[32m    737\u001b[39m             fobj,\n\u001b[32m    738\u001b[39m             validated_mmap_mode,\n\u001b[32m    739\u001b[39m         ):\n\u001b[32m    740\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    741\u001b[39m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[32m    742\u001b[39m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[32m    743\u001b[39m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'supply_chain_recovery_model.pkl'"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib.units import inch\n",
    "import datetime\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "# ----------------------------------\n",
    "# Professional Header Image\n",
    "# ----------------------------------\n",
    "st.image(\n",
    "    \"https://logowik.com/content/uploads/images/maersk-line8921.logowik.com.webp\",\n",
    "    use_container_width=True\n",
    ")\n",
    "\n",
    "# ----------------------------------\n",
    "# Sidebar\n",
    "# ----------------------------------\n",
    "st.sidebar.header(\"üìä Dashboard Controls\")\n",
    "st.sidebar.info(\"Executive dashboard for supply chain risk assessment\")\n",
    "\n",
    "# ----------------------------------\n",
    "# Load Model\n",
    "# ----------------------------------\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    return joblib.load(\"supply_chain_recovery_model.pkl\")\n",
    "\n",
    "model = load_model()\n",
    "\n",
    "# ----------------------------------\n",
    "# PDF Report Generator\n",
    "# ----------------------------------\n",
    "def generate_pdf_report(input_df, prediction, risk_level, importance_df):\n",
    "\n",
    "    buffer = io.BytesIO()\n",
    "    doc = SimpleDocTemplate(buffer, pagesize=A4)\n",
    "    styles = getSampleStyleSheet()\n",
    "    elements = []\n",
    "\n",
    "    elements.append(Paragraph(\"<b>Supply Chain Recovery Prediction Report</b>\", styles[\"Title\"]))\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    elements.append(Paragraph(\n",
    "        f\"Generated on: {datetime.datetime.now().strftime('%d-%m-%Y %H:%M')}\",\n",
    "        styles[\"Normal\"]\n",
    "    ))\n",
    "    elements.append(Spacer(1, 12))\n",
    "\n",
    "    elements.append(Paragraph(\"<b>Input Summary</b>\", styles[\"Heading2\"]))\n",
    "    for col, val in input_df.iloc[0].items():\n",
    "        elements.append(Paragraph(f\"{col}: {val}\", styles[\"Normal\"]))\n",
    "\n",
    "    elements.append(Spacer(1, 12))\n",
    "    elements.append(Paragraph(\"<b>Prediction Result</b>\", styles[\"Heading2\"]))\n",
    "    elements.append(Paragraph(f\"Estimated Recovery Time: <b>{round(prediction)} days</b>\", styles[\"Normal\"]))\n",
    "    elements.append(Paragraph(f\"Risk Level: <b>{risk_level}</b>\", styles[\"Normal\"]))\n",
    "\n",
    "    elements.append(Spacer(1, 12))\n",
    "    elements.append(Paragraph(\"<b>Top Feature Importance</b>\", styles[\"Heading2\"]))\n",
    "\n",
    "    table_data = [[\"Feature\", \"Importance\"]]\n",
    "    for _, row in importance_df.head(10).iterrows():\n",
    "        table_data.append([row[\"Feature\"], round(row[\"Importance\"], 4)])\n",
    "\n",
    "    table = Table(table_data, colWidths=[3.5 * inch, 2 * inch])\n",
    "    elements.append(table)\n",
    "\n",
    "    doc.build(elements)\n",
    "    buffer.seek(0)\n",
    "    return buffer\n",
    "\n",
    "# ----------------------------------\n",
    "# App Title\n",
    "# ----------------------------------\n",
    "st.title(\"Supply Chain Recovery Prediction\")\n",
    "st.markdown(\"Predict **full recovery time (days)** after a supply chain disruption.\")\n",
    "st.divider()\n",
    "\n",
    "# ----------------------------------\n",
    "# Input Form\n",
    "# ----------------------------------\n",
    "with st.form(\"prediction_form\"):\n",
    "\n",
    "    st.subheader(\"üìä Operational Inputs\")\n",
    "    supplier_tier = st.selectbox(\"Supplier Tier\", [1, 2, 3, 4])\n",
    "    disruption_severity = st.slider(\"Disruption Severity (1‚Äì5)\", 1, 5, 3)\n",
    "    production_impact_pct = st.slider(\"Production Impact (%)\", 0.0, 100.0, 25.0)\n",
    "    response_time_days = st.number_input(\"Response Time (Days)\", min_value=0, value=7)\n",
    "    revenue_loss = st.number_input(\"Revenue Loss (USD)\", min_value=0, value=100000)\n",
    "\n",
    "    st.subheader(\"üè∑Ô∏è Contextual Inputs\")\n",
    "    disruption_type = st.selectbox(\"Disruption Type\", [\"Logistics Delay\", \"Natural Disaster\", \"Supplier Bankruptcy\", \"Labor Strike\"])\n",
    "    industry = st.selectbox(\"Industry\", [\"Manufacturing\", \"Automotive\", \"Pharmaceutical\", \"Retail\"])\n",
    "    supplier_region = st.selectbox(\"Supplier Region\", [\"Asia\", \"Europe\", \"North America\", \"South America\"])\n",
    "    supplier_size = st.selectbox(\"Supplier Size\", [\"Small\", \"Medium\", \"Large\"])\n",
    "\n",
    "    submit = st.form_submit_button(\"üîÆ Predict Recovery Time\")\n",
    "\n",
    "# ----------------------------------\n",
    "# Prediction + Dashboard\n",
    "# ----------------------------------\n",
    "if submit:\n",
    "\n",
    "    # ---- Input dataframe ----\n",
    "    input_data = pd.DataFrame([{\n",
    "        \"supplier_tier\": supplier_tier,\n",
    "        \"disruption_severity\": disruption_severity,\n",
    "        \"production_impact_pct\": production_impact_pct,\n",
    "        \"response_time_days\": response_time_days,\n",
    "        \"log_revenue_loss\": np.log1p(revenue_loss),\n",
    "        \"disruption_type\": disruption_type,\n",
    "        \"industry\": industry,\n",
    "        \"supplier_region\": supplier_region,\n",
    "        \"supplier_size\": supplier_size\n",
    "    }])\n",
    "\n",
    "    # ---- Prediction ----\n",
    "    prediction = model.predict(input_data)[0]\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Risk Classification + Visual\n",
    "    # ----------------------------------\n",
    "    st.subheader(\"Risk Visual Indicator\")\n",
    "\n",
    "    if prediction <= 10:\n",
    "        risk_level = \"Low\"\n",
    "        st.image(\n",
    "            \"https://static.vecteezy.com/system/resources/previews/013/916/245/original/low-risk-icon-on-white-background-illustration-eps-10-vector.jpg\",\n",
    "            use_container_width=True\n",
    "        )\n",
    "    elif prediction <= 30:\n",
    "        risk_level = \"Medium\"\n",
    "        st.image(\n",
    "            \"https://static.vecteezy.com/system/resources/previews/002/191/777/large_2x/risk-icon-on-speedometer-medium-risk-meter-isolated-on-white-background-vector.jpg\",\n",
    "            use_container_width=True\n",
    "        )\n",
    "    else:\n",
    "        risk_level = \"High\"\n",
    "        st.image(\n",
    "            \"https://static.vecteezy.com/system/resources/previews/013/916/244/original/high-risk-icon-on-white-background-illustration-eps-10-vector.jpg\",\n",
    "            use_container_width=True\n",
    "        )\n",
    "\n",
    "    # ----------------------------------\n",
    "    # KPI Metrics\n",
    "    # ----------------------------------\n",
    "    st.divider()\n",
    "    st.subheader(\"Executive Summary\")\n",
    "\n",
    "    col1, col2, col3, col4 = st.columns(4)\n",
    "    col1.metric(\"Recovery Time (Days)\", round(prediction))\n",
    "    col2.metric(\"Production Impact\", f\"{production_impact_pct}%\")\n",
    "    col3.metric(\"Revenue Loss\", f\"${revenue_loss:,}\")\n",
    "    col4.metric(\"Disruption Severity\", f\"{disruption_severity}/5\")\n",
    "\n",
    "    # ----------------------------------\n",
    "    # Feature Importance\n",
    "    # ----------------------------------\n",
    "    rf_model = model.named_steps[\"model\"]\n",
    "    preprocessor = model.named_steps[\"preprocessor\"]\n",
    "\n",
    "    importance_df = pd.DataFrame({\n",
    "        \"Feature\": preprocessor.get_feature_names_out(),\n",
    "        \"Importance\": rf_model.feature_importances_\n",
    "    }).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "    st.subheader(\"Feature Importance\")\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.barh(importance_df[\"Feature\"][:15], importance_df[\"Importance\"][:15])\n",
    "    ax.invert_yaxis()\n",
    "    st.pyplot(fig)\n",
    "\n",
    "    # ----------------------------------\n",
    "    # PDF Download\n",
    "    # ----------------------------------\n",
    "    pdf_buffer = generate_pdf_report(\n",
    "        input_data,\n",
    "        prediction,\n",
    "        risk_level,\n",
    "        importance_df\n",
    "    )\n",
    "\n",
    "    st.download_button(\n",
    "        \"Download Executive PDF Report\",\n",
    "        data=pdf_buffer,\n",
    "        file_name=\"supply_chain_recovery_report.pdf\",\n",
    "        mime=\"application/pdf\"\n",
    "    )\n",
    "\n",
    "    st.caption(\"Prediction powered by RandomForest + preprocessing pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad205f74-6d12-4335-8307-cddd31946a55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
